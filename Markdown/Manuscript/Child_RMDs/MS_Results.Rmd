---
title: "MA_Results"
author: "Author"
date: "`r Sys.Date()`"
output: html_document
---

```{r child="../Child_RMDs/MS_Tables.Rmd", echo=FALSE}
```
```{r child="../Child_RMDs/MS_Figures.Rmd", echo=FALSE}
```
<!-- Add child RMDs for results content -->

# Motivation

## Why develop OSHEMs in mental health

Mental disorders impose high health, social and economic burdens worldwide [@RN8;@GBD2019]. Much of this burden is potentially avertable [@RN25], but poorly financed and organised mental health systems are ill-equipped for this challenge[@RN22;@RN23]. The large and widespread additional mental health burdens recently observed during the COVID pandemic[@20211700] and predicted as a potential future consequence of global heating [@page_howard_2010], highlight the need to improve the resilience and adaptability of these systems. To help stem growing demand for mental health services, policymakers have also been encouraged to place greater emphasis on tackling the social determinants of mental disorder[@RN11]. 

<!-- Computational modelling could play an important role in developing policies to improve population mental health but this may require significant changes in the way mental health modelling projects are funded, conceptualised and implemented.  -->

Major mental health reform programs will require the identification, prioritisation, sequencing, targeting and monitoring of multiple interdependent initiatives. Single purpose models that assume static systems may be inadequate for the decision support needs of policymakers and service planners [@PC2020]. Currently, mental health economic models predominantly address issues relating to the affordability and value for money of individual programs [@RN34] with mental health simulation studies rarely modelling complex systems [@RN73]. Greater use of dynamic systems modelling approaches could provide new insights about inter-dependencies between candidate policies and the evolution of the mental health systems planning context [@Occhipinti2021]. These types of models might also be the basis for developing reference models [@Afzali2013] of mental health systems that are intended for multiple-applications and re-use by different modelling teams. 

However, as they are intended for multiple-purposes and because propagation errors may be more likely with more complex models [@Saltelli2019] such models require greater investments in model transparency and validation [@Eddy2012; @Feenstra2022]. The development, validation and maintenance of these more complex models may be simply too onerous a burden for a single modelling team. Developing networks of modellers working on common health conditions [@Sampson2019] and collaborations across multiple modelling teams that include the ability to re-use and extend each others work, can make complex modelling projects more tractable [@Arnold2010]. Similarly, more attention to developing partnerships between modellers and decision-makers across the life-cycle of a modelling project can help ensure models are appropriately conceptualised and implemented and improve their practical utility as decision aids [@Zabell2021]. 

Modelling projects should be resourced to be routinely updated and refined as new evidence emerges and decision contexts change [@Jenkins2021]. There are significant deficits in our understanding of the systems in which mental disorder emerges and is treated [@Fried2020] and longer term project horizons could allow mental health models to progressively improve validity as these gaps are addressed. Currently, the theoretical basis for understanding complex mental health systems is weak [@RN2111]. Strikingly, it remains unclear why increased investments in mental health care have yet to discernibly reduce the prevalence and burden of mental disorders[@RN26].  The literature about how the requirements, characteristics and performance of mental health services are shaped by spatiotemporal context is underdeveloped [@RN42]. There is insufficient evidence to identify the social determinants of mental disorders most amenable to preventative interventions, and for which population sub-groups such interventions would be most effective [@RN43]. 

Open source frameworks have been previously recommended for the development of mental health modelling field [@RN73] but, as with health economics more generally, OSHEMs remain rare. Currently there is only one mental health related model (in Alcohol Use Disorder [@Basu2018]) that is indexed in the Open Source Models Clearinghouse [@OSMC_20xx;@Emerson2019]. A Major Depressive Disorder reference model for the United States [@IVIMDD2022] is also being developed as part of the Open Value Initiative [@Jansen2019]. We believe greater support for open source approaches have the potential to provide more transparent, collaborative and sustained approaches to mental health system model development. 

## readyforwhatsnext
We are currently developing readyforwhatsnext, a reference OSHEM that aims to examine multiple potential population level strategies for promoting mental wellbeing and preventing and treating mental disorders in young people.

Our approach to model development is to undertake a number of discrete modelling projects of the people, places, platforms and programs that shape the mental health and wellbeing of young people and to progressively link them together by means of a common framework. To model people we are developing synthetic representations of populations of interest [@DVN/HJXYKQ_2021] that describe relevant individual characteristics and their household relationships, algorithms that map psychological measures to health utility [@Hamilton2021.07.07.21260129] and choice models for predicting the helpseeking behaviour of young people. Our in development model of places [@DVN/V3OKZV_2022] aims to synthesise geometry and spatial attribute data to characterise the geographic distribution of relevant demographic, environmental, epidemiological and service infrastructure features and our first model of a service platform will represent the processes and operations of a complex primary youth mental health service. We also plan to extend our prior work reviewing economic evidence relating to youth mental health programs [@RN33] so that it can be integrated with the model.

Our initial work on readyforwhatsnext is focused on Victoria, Australia but the framework we are using to develop it is designed to facilitate extension by ourselves and others to different decision contexts. Progress is reported on a project website [@rfwn2022].

# Framework
The framework we have developed to implement readyforwhatsnext consists of specified standards for OSHEMs and tools for meeting those standards.

## Standards
We have identified 20 standards that we believe are important for quality implementations of OSHEMs, each described under one of following six principles for making models TIMELY:

 - **Transparent**: people can easily see how a model has been implemented and tested;
 - **Iterative**: a model is routinely updated to maintain and improve validity;
 - **Modular**: models and their components can be combined to extend their scope;
 - **Epitomized**: models can be used in multiple decision contexts;
 - **Licensed**: a model and its derivatives are persistently re-usable by other modellers; and
 - **Yielding**: a model can be reliably deployed as a simple and flexible decision aid.

### Transparent Models
A range of tools and practices are available to help make model code and data accessible, citable and comprehensible. The most efficient way to widely disseminate code and data may be to use existing open science infrastructure [@Erdemir2020]. Repositories such as Zenodo [@Zenodo2013] and Dataverse [@Dataverse2007] provide persistent storage solutions that generate a Digital Object Identifier (DOI) for each unique item. These repositories are a preferable solution for sharing citable code and data than transitory repositories such as corporate websites or GitHub where items can be deleted or relocated at any time [@sseditors2022]. Zenodo includes tools that automate integration with GitHub, which makes it easy for developers to maintain parallel code repositories - one for disseminating the most up to date development code and the other for archiving citable code releases.

Model code and data also need to be clearly documented, potentially with different versions for technical and non-technical users [@Eddy2012]. Developers storing data in a Dataverse installation have access to multiple meta-data fields to document both a data collection and its constituent individual files. In R, code manuals and websites can be created with the aid of tools such as devtools [@devtools2021], sinew [@sinew2022], roxygen2 [@roxygen2021] and pkgdown [@pkgdown2022]. 

Consistent use of meaningful naming conventions when authoring code is recommended [@Wilson_2017; @Alarid2019]. The main logic of a program can be made comprehensible to even non-technical users though the use of the common practices of abstraction [@8717448], where only simple, high level commands are routinely exposed to reviewers, and polymorphsim [@7181447], where the same command (e.g. "simulate") can be reused to implement different algorithms of the same broad type. Literate programming, where tools like RMarkdown [@xie2018r] are used to render documents that integrate computer code with plain English descriptions of each step in an analysis workflow, can make code easier to follow by both technical and non-technical users. 

An essential component of quality assuring health economic models is verification - ensuring that calculations are correct and consistent with model specifications [@techver2019]. One useful concept for informing model users about the extensiveness of verification checks is code coverage [@ERICWONG2010188] - the proportion of model code that has been explicitly tested. In R, the testthat [@testthat2011] and covr [@covr2020] tools can be used in conjunction with GitHub to define tests and report coverage metrics.

Finally, transcription errors - mistakes introduced when transferring data between sources, models and reports - are very common in health economic models [@Radeva2020]. The risk of these errors might be lower if there was full transparency across all steps in a study workflow. Scientific computing tools now make it relatively straightforward to author programs that reproducibly execute all steps in data ingest, processing and reporting [@Wilson_2017].

Standards:

- **T1: Uniquely identified copies of model code and data are permanently archived in open online repositories**
<!-- T2 MISSING - Merged With T1 -->

- **T2: Model code and data are documented **<!-- Was T3 -->

- **T3: Model code uses a simple and consistent syntax**<!-- Was T4 -->

- **T4: Model analyses and reporting are implemented using literate programming** <!-- Was T5 -->

- **T5: Code coverage is reported** <!-- New, replaces version now moved to T4 -->

- **T6: All parts of a study analysis and reporting workflow can be reproduced and/or replicated** <!-- Was T7, Replaces Deleted T6 -->

### Iterative Models
To avoid OSHEMs going stale - losing validity and usefulness with time - they should be routinely updated. A number of tools and approaches can make the process of implementing and curating changes to model code and data more coherent and efficient.  Repositories such as Zenodo [@Zenodo2013] and Dataverse [@Dataverse2007] provide persistent access to all published versions of a dataset, each uniquely identifiable. For code, use of version control tools like Git [@git20XX] can ensure that the entire development history of a project is organised so that each version is distinguishable and retrievable by developers. The online platform GitHub [@github2007] can make this version history accessible to anyone.

Adopting semantic versioning [@semver20xx] conventions can be an efficient way to provide users of model code and data with information about the potential importance of an update. For R code, the usethis [@usethis2021] package can be used to partially automate version number increments using the convention Major.Minor.Patch.Development. Datasets stored on the Harvard Dataverse use the simpler Major.Minor convention. 

Continuous integration [@CI2017] tools can help verify that each code update passes multiple quality tests. OSHEMs developed in R can take advantage of templates provided by devtools [@devtools2021] and pkgdown [@pkgdown2022] to run continuous integration checks on GitHub. These tests can include those of units (do individual functions produce expected output?), documentation (does documentation render correctly?, can all example workflows be executed?) and installation (can the software be successfully deployed on multiple types of operating system?).

Finally, using deprecation conventions that take an informative and staged approach to retiring old code and data reduces the risk that model revisions have unintended consequences on third party users. The package lifeycle [@lifecycle2021] provides tools for R developers to consistently deprecate their code.

Standards:

- **I1: Model code is version controlled** <!-- Was I2 -->

- **I2: Model code and data use semantic versioning** <!-- Was I1 -->

- **I3: Continuous integration is used to verify model code updates**

- **I4: Deprecation conventions are used to retire model code and data**

### Modular Models
Modular health economic models link multiple self-contained components that can be independently reused and extended by other projects [@Trauer2017;@Urach2013]. 

Many types of mental health data are highly sensitive with strict confidentiality requirements. For this reason, not all data included in some mental health models can be made widely available for others to re-use. A modular approach that ensures that model code and data are decoupled (stored in different files) can help model developers to restrict access to confidential model data, while providing open access to all other model components. 

An important consideration when combining model components (or modules) is to ensure that interactions between two modules do not compromise the validity of either. Using the coding practice of encapsulation [@8717448] can help ensure that model modules can be safely combined [@ready4oop2022].

Standards:

- **M1: Model code and data are stored and managed separately** <!-- Modified (lost ref to licensed and cited) -->

- **M2: Model code defines encapsulating data structures** <!--Replacement - Old version now merged with E1 -->

### Epitomised Models
A key challenge to generalising health economic models is that they are typically developed to inform a decision problem with a highly specific jurisdictional context. However, a number of choices about how these models are implemented can significantly increase the re-usability of model code in other contexts. 

Writing code as collections of functions (short, self-contained and reusable algorithms that each perform a discrete task) is recommended as good practice for scientific computing [@Wilson_2017]. When distributed as libraries (for example, as R packages), functions have the potential to be widely re-used, often in contexts very different than those they were originally developed for. A special type of function called a method can only be applied to a pre-defined class of data structure. Due to the coding concept of inheritance [@8717448], the more restricted nature of methods can be used to enhance the re-usability of model code in different decision contexts [@ready4oop2022]. For example, when generalising a model developed for the Australian context to a UK context, one could create a class that initially inherits all of the methods defined for the Australian model and then write new or replacement methods as needed for the UK model.

Whatever type of functions are written for a modelling project, it is good practice to make available test or toy data to demonstrate their use [@Wilson_2017].

Standards:

- **E1: Model code is distributed as libraries of classes and functions**  <!-- Modified (lost ref to OOP and merged with M2) -->

- **E2: Model code defines inheriting data-structures**

- **E3: Test data is available to demonstrate generalised model applications**


### Licensed Models
```{r}
# Adapted fom: https://seankross.com/2016/08/02/How-R-Packages-are-Licensed.html
sorting_hat <- function(student, houses){
  choice <- purrr::map_lgl(houses, grepl, x = student)
  if(!any(choice)){
    return("Other")
  } else {
    return((houses[choice])[1])
  }
}
license_table <- table(utils::available.packages()[,"License"])
names(license_table) %<>%
  purrr::map_chr(function(x){
    sorting_hat(x, c("Apache", "Artistic", "CC", "BSD", "MIT", "GPL"))
  })  
license_tbl <- as.data.frame(license_table) %>%
  dplyr::rename(License = Var1) %>%
  dplyr::group_by(License) %>%
  dplyr::summarize(Freq = sum(Freq)) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(dplyr::desc(Freq))
#licenses <- license_tbl$Freq
gpl_pc_dbl <- round(license_tbl$Freq[license_tbl$License=="GPL"]/sum(license_tbl$Freq)*100,2) 
```

To make model code and data widely re-usable by others, it is important to provide users with appropriate and explicit permissions. In the context of open source models, there are two broad categories of licensing options. Some guidance strongly recommends the use of permissive licensing [@Wilson_2017] that provides users with great flexibility as to the purposes (including commercial) for which the content could be re-used. An alternative approach is to use copyleft licenses [@copyleft2022] that can require content users to distribute any derivative works they create under similar open source arrangements.

For code, it may be appropriate to adopt the prevailing open source licensing practice within the programming language being used. Applying a previously published algorithm [@kross2016] to analyse the most comprehensive archive of released R packages [@CRAN2022] finds that `r `gpl_pc_dbl`% are distributed under various forms of General Public License (GPL) [@GNUGPL2022], a copyleft license.

For data, it may not be sufficient to simply choose between a permissive license like the Public Domain Dedication (CC0) [@cc02022] or a copyleft option such as the Attribution-Share Alike (CC-BY-SA) [@bysa2022]. Responsible custodianship of some de-identified mental health data may involve using or adapting template terms of use [@sampleterms2022] which have a number of ethical clauses (for example, prohibiting efforts to re-identify research participants). 

Licenses may or may not specify that model re-users must give appropriate acknowledgement to model authors. Citation tools can be distributed with each cite individual code or data items to inform re-users of the desired attribution. In R, including a CITATION file in the `inst` directory of a package will enable users of that package to retrieve citation information by running a command of the format `citation("Package Name")` in the R console. More generally, including a CITATION.cff file at the top level of any software item (including those written in R), will enable GitHub and Zenodo repositories hosting that item to include the relevant information in their citation tools. Datasets hosted on Dataverse installations have metadata fields that, once completed by authors, generate citation files for dataset viewers.

Standards:

- **L1: Model code is made available for re-use under copyleft licenses**

- **L2: Non-confidential model data is available for liberal re-use (subject to additional terms for de-identified human data)**

- **L3: Model code and data are distributed with tools to support appropriate citation** <!-- New -->

### Yielding Models
OSHEMs can be time and skills intensive for modellers to develop - but they should be easy for others to use. 

Statistical models are a common output of health economic evaluations, but they are often not reported in a format that enables others to confidently and reliably re-use them [@Kearns2013]. Open source approaches can help address this by disseminating code artefacts that enable easy and appropriate use of a statistical model to make predictions with new data. However, great care must be exercised when doing so if models are derived from data on human subjects. In the R language, model objects by default typically contain a copy of the source dataset. Such dataset copies must therefore be replaced (for example, with fake data) and the amended artefact's predictive performance then retested before any public release.

Another way to make OSHEMs easier to use is to develop simple user-interfaces for non-technical users. In R, such user-interfaces are typically developed with the Shiny package, for which a tutorial aimed at health economists is available [@SmithR2020].

Standards:

- **Y1: Statistical models can be safely and appropriately reused using standardised toolkits** <!-- New, Replaces Old Y1 (now Y2) -->
- **Y2: Non-technical users can configure and run models via simple user-interfaces** <!-- Was Y1 -->

## Toolkits
We have developed a toolkit to help streamline the process of developing OSHEMs that meet the TIMELY standards. The toolkit is comprised of online repositories and software.

### Online Repositories
We have created a GitHub organisation (https://github.com/ready4-dev) for in development model code, a Zenodo community (https://zenodo.org/communities/ready4) for citable archived code and a Dataverse on the Harvard Dataverse for model data (https://dataverse.harvard.edu/dataverse/ready4).

```{r, child = child_docs_ls$one, echo=FALSE}
```

### Software
We have written six R packages to support the development and curation of model code and data. The package ready4 defines the framework's syntax and a model module template class. The ready4class package provides tools for creating self-documenting model module classes, while ready4fun is a toolkit for creating the functions (including methods) that are also self-documenting and written in a consistent house style. Model module classes and functions are bundled into R packages with standardised approaches to quality assurance and documentation using the the ready4pack package. Tools for creating and managing model data are included in the ready4use package, while tools for the analysis and reporting of models are included in the ready4show package. The purpose of each package, the TIMELY standards they support and the third party R packages they depend on are summarised in Table 1. <!-- Autogenerate ref -->



# Application

Worked example
