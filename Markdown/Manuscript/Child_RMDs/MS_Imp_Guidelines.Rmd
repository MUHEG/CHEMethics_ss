---
title: "MS_Imp_Guidelines"
output: html_document
date: '2022-07-21'
---

Based on published guidance on computational modelling in health economics and other disciplines and our own experience, we have identified 20 standards that we believe are important for implementing a MOSHEM that is accountable (seven standards), reusable (nine standards) and updatable (four standards). The standards are specified in Table \@ref(tab:timelygls) and are discussed below.

 <!-- - **Transparent**: people can easily see how a model has been implemented and tested; -->
 <!-- - **Iterative**: a model is routinely updated to maintain and improve validity; -->
 <!-- - **Modular**: models and their components can be combined to extend their scope; -->
 <!-- - **Epitomising**: model code is sufficiently general to be be re-used in multiple decision contexts; -->
 <!-- - **Licensed**: a model, its components and derivatives are persistently re-usable by other modellers; and -->
 <!-- - **Yielding**: a model can be simply, flexibly and reliably used as a decision aid. -->

```{r, child = child_docs_ls$one, echo=FALSE}
```

### Standards for an accountable MOSHEM
Guidance on transparency in health economic modelling published over ten years ago [@Eddy2012] made recommendations on documenting models but notably did not include recommendations on sharing model code and data. However, more recent and multidisciplinary healthcare modelling guidance [@Erdemir2020] recommends using existing digital repository services to these types of digital model artefacts. Some types of repository such as GitHub [@github2007] provide tools for disseminating work in progress code and providing highly transparent records of the complete development history and individual authorship contributions of a software project, while others such as Zenodo [@Zenodo2013] and Dataverse [@Dataverse2007] provide persistent storage solutions that generate a Digital Object Identifier (DOI) for each code and data collection. 

Model code and data should be clearly documented, potentially with different versions for technical and non-technical users [@Eddy2012]. <!-- nd --> Consistent use of meaningful naming conventions when authoring code is recommended [@Wilson_2017; @Alarid2019]. Code can be made easier to follow by using the practices of abstraction [@8717448], where only simple, high level commands are routinely exposed to reviewers, and polymorphism [@7181447], where the same command (e.g. "simulate") can be reused to implement different algorithms of the same type. Programs to implement model analyses can be made comprehensible to even non-technical users through the use of literate programming techniques <!-- that use tools like RMarkdown [@xie2018r]  -->that integrate computer code with plain English descriptions. 

An essential component of quality assuring health economic models is verification - ensuring that calculations are correct and consistent with model specifications [@techver2019]. One useful concept for informing model users about the extensiveness of verification checks is code coverage [@ERICWONG2010188] - the proportion of model code that has been explicitly tested. <!-- In R, the testthat [@testthat2011] and covr [@covr2020] tools can be used in conjunction with GitHub to define tests and report coverage metrics. -->Transcription errors - mistakes introduced when transferring data between sources, models and reports - are very common in health economic models [@Radeva2020]. The risk of these errors might be lower if there was full transparency across all steps in a study workflow. Scientific computing tools now make it relatively straightforward to author programs that reproducibly execute all steps in data ingest, processing and reporting [@Wilson_2017].

Code and data should be distributed with tools that make it easy for potential users to appropriately cite each model artefact. 

<!-- Guidelines: -->

<!-- - **T1: Uniquely identified copies of model code and data are permanently archived in open online repositories** -->
<!-- <!-- T2 MISSING - Merged With T1 --> 

<!-- - **T2: Model code and data are documented **<!-- Was T3 --> 

<!-- - **T3: Model code uses a simple and consistent syntax**<!-- Was T4 --> 

<!-- - **T4: Model analyses and reporting are implemented using literate programming** <!-- Was T5 --> 

<!-- - **T5: Code coverage is reported** <!-- New, replaces version now moved to T4 --> 

<!-- - **T6: All parts of a study analysis and reporting workflow can be reproduced and/or replicated** <!-- Was T7, Replaces Deleted T6 --> 

<!-- - **L3: Model code and data are distributed with tools to support appropriate citation** <!-- New --> 

<!-- and the use of version control systems. <!-- such as Git [@git20XX].  -->  
<!-- Repositories such as Zenodo [@Zenodo2013] and Dataverse [@Dataverse2007] provide persistent storage solutions that generate a Digital Object Identifier (DOI) for each unique item. These repositories are a preferable solution for sharing citable code and data than transitory repositories such as corporate websites or GitHub where items can be deleted or relocated at any time [@sseditors2022]. Zenodo includes tools that automate integration with GitHub, which makes it easy for developers to maintain parallel code repositories - one for disseminating the most up to date development code and the other for archiving citable code releases. --> <!-- Developers storing data in a Dataverse installation have access to multiple meta-data fields to document both a data collection and its individual constituent files.  --><!-- In R, code manuals and websites can be created with the aid of tools such as devtools [@devtools2021], sinew [@sinew2022], roxygen2 [@roxygen2021] and pkgdown [@pkgdown2022].  -->


### Standards for a reusable MOSHEM
<!-- ## Licensed models -->
```{r echo = F}
gpl_pc_dbl <- get_license_share("GPL")
```

To make model code and data widely re-usable by others, it is important to provide users with appropriate and explicit permissions. In the context of open source models, there are two broad categories of licensing options. Some guidance strongly recommends the use of permissive licensing [@Wilson_2017] that provides users with great flexibility as to the purposes (including commercial) for which the content could be re-used. An alternative approach is to use copyleft licenses [@copyleft2022] that can require content users to distribute any derivative works they create under similar open source arrangements. For code, it may be appropriate to adopt the prevailing open source licensing practice within the programming language being used. For data, it may not be sufficient to simply choose between a permissive license like the Public Domain Dedication (CC0) [@cc02022] or a copyleft option such as the Attribution-Share Alike (CC-BY-SA) [@bysa2022]. In addition to ensuring that data is ethically appropriate for disseminate in open access repositories, responsible custodianship of some de-identified or aggregated data may involve using or adapting template terms of use [@sampleterms2022] which have a number of ethical clauses (for example, prohibiting efforts to re-identify research participants). 

Storing and managing model code and data separately, can make it easier to apply models to different decision contexts and, when necessary, to selectively restrict access to data that are confidential, while disseminating all other model artefacts. Clear distinctions should be made between model modules (code that defines abstract data structures and the algorithms that can be applied to data described by these structures), model datasets (digital information such as parameter values, unit records, etc) and model analyses (code that specifies the data to be supplied to modules and selects which module algorithms to apply to that data).

The coding practice of encapsulation [@8717448] can be used to help ensure that model modules can be safely combined [@ready4oop2022]. In some cases, combining modules may mean new versions of modules have to be created that account for their effects on each other. The coding concept of inheritance [@8717448] can be used to efficiently achieve this objective as well as to facilitate selective editing of modules when transferring models to different decision contexts [@ready4oop2022]. Writing algorithms as collections of functions (short, self-contained and reusable software routines that each perform a discrete task) is recommended as good practice for scientific computing [@Wilson_2017]. Functions to implement model algorithms can be associated with module data structures (also known as a class) via a special type of function called a method. Model modules of a similar type or purpose can be efficiently distributed and documented by bundling them as code libraries. It is good practice to make available test or toy data to demonstrate the use of model algorithms [@Wilson_2017].

<!-- When bundled for distribution as libraries<!-- (for example, as R packages) -->
<!-- , functions have the potential to be widely re-used, often in contexts very different than those they were originally developed for.  --> 
<!-- A special type of function, called a method, can only be applied to a pre-defined class of data structure.  -->

<!-- ## Yielding models --><!-- MOSHEMs can be time and skills intensive for modellers to develop - but they should be easy for others to use.  -->
Statistical models are a common output of health economic evaluations, but they are often not reported in a format that enables others to confidently and reliably re-use them [@Kearns2013]. Open source approaches can help address this by disseminating code artefacts that enable easy and appropriate use of a statistical model to make predictions with new data. However, great care must be exercised when doing so if models are derived from data on human subjects as some software artefacts by default contain a copy of the source dataset. Such dataset copies must therefore be replaced (for example, with synthetic data) and the amended artefact's predictive performance then retested before any public release. Another way to make MOSHEMs easier to use is to develop simple user-interfaces for non-technical users. In the open source R language, such user-interfaces are typically developed with the Shiny package, for which a tutorial aimed at health economists is available [@SmithR2020].

<!-- Applying a previously published algorithm [@kross2016] to analyse the most comprehensive archive of released R packages [@CRAN2022] finds that `r gpl_pc_dbl`% are distributed under various forms of General Public License (GPL) [@GNUGPL2022], a copyleft license. -->
<!-- In R, including a CITATION file in the `inst` directory of a package will enable users of that package to retrieve citation information by running a command of the format `citation("Package Name")` in the R console [@Salmon2021]. More generally, including a CITATION.cff file at the top level of your code repository will enable GitHub and Zenodo repositories hosting that item to include the relevant information in their citation tools [@Druskat_Citation_File_Format_2021]. Datasets hosted on Dataverse installations have metadata fields that, once completed by authors, generate citation files for dataset viewers. -->


<!-- A key challenge to generalising health economic models is that they are typically developed to inform a decision problem with a highly specific jurisdictional context. However, a number of choices about how these models are implemented can significantly increase the re-usability of model code in other contexts.  -->
<!-- For example, when generalising a model developed for the Australian context to a UK context, one could create a class that initially inherits all of the methods defined for the Australian model and then write new or replacement methods as needed for the UK model.  -->
<!-- Guidelines: -->

<!-- - **L1: Model code is made available for re-use under copyleft or permissive licenses** -->

<!-- - **L2: Non-confidential model data is licensed for liberal re-use (subject to additional terms for de-identified human data)** -->

<!-- - **E2: Model code defines inheriting data-structures** --> <!-- Order changed--> 

<!-- - **E1: Model code is distributed as libraries of classes and functions**  <!-- Modified (lost ref to OOP and merged with M2) --> 

<!-- - **E3: Test data is available to demonstrate generalised applications of model code** -->

<!-- - **M1: Model code and data are stored and managed separately** <!-- Modified (lost ref to licensed and cited) --> 

<!-- - **M2: Model code defines encapsulating data structures** <!--Replacement - Old version now merged with E1 --> 

<!-- - **Y1: Statistical models are distributed with validated tools to support their safe and appropriate re-use** <!-- New, Replaces Old Y1 (now Y2) --> 
<!-- - **Y2: Simple user-interfaces allow non-technical users to configure and run models ** <!-- Was Y1 --> 

### Standards for an updatable MOSHEM
To avoid MOSHEMs going stale - losing validity and usefulness with time - they should be routinely updated.  Each update of code and data should be uniquely identifiable and retrievable, a goal that can be facilitated by use of version control tools [@Erdemir2020]. Labeling each change using semantic versioning [@semver20xx] conventions can signal the potential importance of an update to users of model code and data. Continuous integration [@CI2017] tools can help verify that each code update passes multiple quality tests. Finally, using deprecation conventions that take an informative and staged approach to retiring old code and data reduces the risk that model revisions have unintended consequences on third party users.  

<!-- A number of tools and approaches can make the process of implementing and curating changes to model code and data more coherent and efficient.   <!-- Repositories such as Zenodo [@Zenodo2013] and Dataverse [@Dataverse2007] provide persistent access to all published versions of a dataset, each uniquely identifiable. For code, use of version control tools like Git [@git20XX] can ensure that the entire development history of a project is organised so that each version is distinguishable and retrievable by developers. The online platform GitHub [@github2007] can make this version history accessible to anyone. -->

<!-- For R code, the usethis [@usethis2021] package can be used to partially automate version number increments using the convention Major.Minor.Patch.Development (e.g. ExampleSoftware v1.1.1.1). Datasets stored on the Harvard Dataverse use the simpler Major.Minor convention.  -->
<!-- MOSHEMs developed in R can take advantage of templates provided by devtools [@devtools2021] and pkgdown [@pkgdown2022] to run continuous integration checks on GitHub.  --><!-- These tests can include those of units (do individual functions produce expected output?), documentation (does documentation render correctly?; can all example workflows be executed?) and installation (can the software be successfully deployed on multiple types of operating system?).  -->

<!-- The package lifeycle [@lifecycle2021] provides tools for R developers to consistently deprecate their code. -->

<!-- Guidelines: -->

<!-- - **I1: Model code and data are version controlled** <!-- Was I2 --> 

<!-- - **I2: Model code and data use semantic versioning** <!-- Was I1 --> 

<!-- - **I3: Continuous integration is used to verify model code updates** -->

<!-- - **I4: Deprecation conventions are used to retire model code and data** -->









